{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Problem Statement\n",
    "\n",
    "The challenge is to develop a chatbot that accurately replicates an individual’s unique chat style based on their WhatsApp messages."
   ],
   "metadata": {
    "id": "0jxLGekwq-Uv"
   },
   "id": "0jxLGekwq-Uv"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id"
   },
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Acquisition\n",
    "\n",
    "- **Source:** WhatsApp chat logs.\n",
    "- **Key Features (Input):**\n",
    "  - Message content\n",
    "  - Timestamps\n",
    "  - Sender info\n",
    "  - Conversation context\n",
    "- **Output Needed:** Responses that reflect the target person’s communication style."
   ],
   "metadata": {
    "id": "v6y49OC37WIu"
   },
   "id": "v6y49OC37WIu"
  },
  {
   "metadata": {
    "id": "72010360d8f13de1",
    "outputId": "96124fdf-cc72-453e-866f-7fc17f0693f7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "datetime_formats = [\"%d/%m/%y, %H:%M\", \"%m/%d/%y, %H:%M\", \"%d/%m/%y %H:%M:%S\", \"%d/%m/%Y %H:%M\"]\n",
    "stop_words = ['created group', 'business account', 'Messages and calls are end-to-end encrypted', 'is a contact', 'deleted this message', 'voice call', '未接语音通话', '消息和通话都进行端到端加密', '语音通话', '这条消息已被删除']\n",
    "DIRECTORY = './data/'\n",
    "FILES = [f for f in os.listdir(DIRECTORY) if f.endswith('.txt')]\n",
    "print(FILES)\n",
    "\n",
    "def get_datapoint(line: str):\n",
    "    match = re.search(r'\\[?(\\d{2}\\/\\d{2}\\/\\d{2} \\d{2}:\\d{2}:\\d{2}|\\d{1,2}\\/\\d{1,2}\\/\\d{2}, \\d{2}:\\d{2})\\]? (?:- )?(.*?): ?(.+)', line)\n",
    "    if match is None:\n",
    "      return line.strip(),\n",
    "    date, author, message = match.groups()\n",
    "    return date, author, message\n",
    "\n",
    "\n",
    "def get_datetime_format(filename):\n",
    "    formats = [\"%d/%m/%y, %H:%M\", \"%m/%d/%y, %H:%M\", \"%d/%m/%y %H:%M:%S\", \"%d/%m/%Y %H:%M\"]\n",
    "    with open(f\"{DIRECTORY}{filename}\", encoding='utf-8') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            date = re.search(r'^\\[?(.*?)(?:\\]| -)', line)\n",
    "            if date is None:\n",
    "                continue\n",
    "            for i, format in enumerate(formats):\n",
    "                try:\n",
    "                    datetime.strptime(date.group(1), format)\n",
    "                except ValueError:\n",
    "                    formats.pop(i)\n",
    "            if len(formats) == 1:\n",
    "              break\n",
    "        return formats[0]\n",
    "\n",
    "\n",
    "def load(file):\n",
    "  res = []\n",
    "  with open(f\"{DIRECTORY}{file}\", encoding=\"utf-8\") as fp:\n",
    "    lines = fp.readlines()\n",
    "    counter = 0\n",
    "    DATETIME_FORMAT = get_datetime_format(file)\n",
    "    date, time, author = None, None, None\n",
    "    message_buffer = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "      if any(i in line for i in stop_words):\n",
    "        continue\n",
    "      line = line.replace(u'\\u200e', '')\n",
    "      message_data = get_datapoint(line)\n",
    "\n",
    "      if len(message_data) == 1:\n",
    "        message_buffer.append(message_data[0])\n",
    "      else:\n",
    "        if len(message_buffer) > 0:\n",
    "          if date is None: continue\n",
    "          date_parsed = datetime.strptime(date, DATETIME_FORMAT)\n",
    "          res.append([date_parsed, author, ' '.join(message_buffer)])\n",
    "          counter += 1\n",
    "        message_buffer.clear()\n",
    "        date, author, message = get_datapoint(line)\n",
    "        try:\n",
    "          date_parsed = datetime.strptime(date, DATETIME_FORMAT)\n",
    "          if date_parsed:\n",
    "            message_buffer.append(message)\n",
    "        except ValueError:\n",
    "          pass\n",
    "\n",
    "  print(f\"Loaded {file} with {counter} datapoints\")\n",
    "  return res"
   ],
   "id": "72010360d8f13de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "76e252520e8e5639",
    "outputId": "a50e6b9d-9dc0-471b-c565-f3643fcc2c18",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "for f in FILES:\n",
    "  data.extend(load(f))\n",
    "print(len(data), \"datapoints in total.\")"
   ],
   "id": "76e252520e8e5639",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6d3a4509371ad84b"
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(data, columns=[\"Date\", 'Author', 'Message'])\n",
    "prev_datetime = df[\"Date\"].shift(periods=1)\n",
    "df[\"time_delta\"] = (df[\"Date\"] - prev_datetime).dt.total_seconds()\n",
    "df = df.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "authors = list(df.Author.unique())\n",
    "authors"
   ],
   "id": "6d3a4509371ad84b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D4xqmuzVET3_",
    "outputId": "97c975fe-7088-499e-e37d-d7040943d2a1"
   },
   "id": "D4xqmuzVET3_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Here we analyze the number of messages per day"
   ],
   "metadata": {
    "id": "M9GGyUV87dy0"
   },
   "id": "M9GGyUV87dy0"
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "grouped = df.groupby(df['Date'].dt.date).agg({'Message': 'count'}).reset_index()\n",
    "sns.lineplot(data=grouped, x='Date', y='Message')\n",
    "plt.fill_between(grouped['Date'], grouped['Message'], color='skyblue', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.title('Number of Messages Sent per Day')\n",
    "plt.ylim(0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "Qa7bCXJFt1Y_",
    "outputId": "d2a0bd61-504b-4836-ee46-79e9a9b9202b"
   },
   "id": "Qa7bCXJFt1Y_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "resampled = df.set_index('Date').resample('D').count().fillna(0)\n",
    "max_date = resampled['Message'].idxmax()\n",
    "max_messages = resampled.loc[max_date, 'Message']\n",
    "avg_messages = resampled['Message'].mean()\n",
    "\n",
    "print(f\"Most messages sent on {max_date.strftime('%Y-%m-%d')} at {max_messages} messages\")\n",
    "print(f\"On average, {avg_messages} messages are sent per day\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE7YrAVpHvHH",
    "outputId": "75c06749-eaca-401b-f39c-e1b1b6264a63"
   },
   "id": "yE7YrAVpHvHH",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['Day'] = df['Date'].dt.day_name()\n",
    "\n",
    "pivot = df.pivot_table(index='Day', values='Message', aggfunc='count')\n",
    "pivot = pivot.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.heatmap(pivot, annot=True, fmt='d')\n",
    "plt.title('Number of messages sent per day of the week')\n",
    "plt.ylabel('Day of the week')\n",
    "plt.xlabel('Number of messages')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "sUrOsQo90PG0",
    "outputId": "6b714a2e-0d16-4284-9977-b1b480c716dd"
   },
   "id": "sUrOsQo90PG0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['Hour'] = df[\"Date\"].dt.hour\n",
    "pivot = df.pivot_table(index='Hour', values='Message', aggfunc='count')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt='d')\n",
    "plt.title('Number of messages sent per hour of the day')\n",
    "plt.ylabel('Hour of the day')\n",
    "plt.xlabel('Number of messages')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "eYRIoyWQ0gw3",
    "outputId": "1a626451-a7b6-4a93-8d7a-3515c8a04942"
   },
   "id": "eYRIoyWQ0gw3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning\n",
    "\n",
    "a) Removed specific text patterns (e.g., \"<Media omitted>\", URLs)\n",
    "\n",
    "b) Filtered out excessively long messages (above 99th percentile)\n",
    "\n",
    "c) Merged messages from the same author within short time frames\n",
    "\n",
    "d) Standardized punctuation and removed repetitive characters"
   ],
   "metadata": {
    "id": "TeaJA7Cg7p5Z"
   },
   "id": "TeaJA7Cg7p5Z"
  },
  {
   "metadata": {
    "id": "f02cee984111e18d",
    "outputId": "9fa3382a-0f8a-446d-d9e8-e9c628296b22",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "texts_to_remove = ['<Media omitted>', '<This message was edited>', 'https?://\\S+', '13135550002']\n",
    "df = df[~df['Message'].str.contains('|'.join(texts_to_remove), regex=True)]\n",
    "df = df[df['Message'].str.strip().astype(bool)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ],
   "id": "f02cee984111e18d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove excessively long messages"
   ],
   "metadata": {
    "id": "VnU1v5yx7ubI"
   },
   "id": "VnU1v5yx7ubI"
  },
  {
   "metadata": {
    "id": "3322692948c5f62c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "348feb02-ddfb-40f1-9460-b2920e70f71d"
   },
   "cell_type": "code",
   "source": [
    "df['Word_Count'] = df['Message'].apply(lambda x: len(x.split()))\n",
    "print(f\"Removing messages with more than 50 words\")\n",
    "df = df[df['Word_Count'] <= 50]\n",
    "df.shape"
   ],
   "id": "3322692948c5f62c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Join messages sent by the same author that are sent in the same time frame together, lengthening the responses."
   ],
   "metadata": {
    "id": "gK6t_yq57xYO"
   },
   "id": "gK6t_yq57xYO"
  },
  {
   "metadata": {
    "id": "8bbb23ec3067ae01"
   },
   "cell_type": "code",
   "source": [
    "merged_messages = []\n",
    "current_author = None\n",
    "current_message = []\n",
    "current_datetime = None\n",
    "current_word_count = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    author = row['Author']\n",
    "    message = row['Message']\n",
    "    datetime = row['Date']\n",
    "    word_count = row['Word_Count']\n",
    "\n",
    "    if author == current_author and current_word_count + word_count <= 50:\n",
    "        current_message.append(message)\n",
    "        current_word_count += word_count\n",
    "        current_datetime = min(current_datetime, datetime)\n",
    "    else:\n",
    "        if current_message:\n",
    "            merged_messages.append({\n",
    "                'Author': current_author,\n",
    "                'Message': ' '.join(current_message),\n",
    "                'Datetime': current_datetime\n",
    "            })\n",
    "\n",
    "        current_author = author\n",
    "        current_message = [message]\n",
    "        current_datetime = datetime\n",
    "        current_word_count = word_count\n",
    "\n",
    "if current_message:\n",
    "    merged_messages.append({\n",
    "        'Author': current_author,\n",
    "        'Message': ' '.join(current_message),\n",
    "        'Datetime': current_datetime\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(merged_messages)"
   ],
   "id": "8bbb23ec3067ae01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "1e9c5abed9223488",
    "outputId": "799c59d6-7c03-4326-e49b-40bd716307e6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "id": "1e9c5abed9223488",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we look at the word count distribution of the new merged messages"
   ],
   "metadata": {
    "id": "nUgoCBhN8Bli"
   },
   "id": "nUgoCBhN8Bli"
  },
  {
   "metadata": {
    "id": "685e4f364780f966",
    "outputId": "05927d24-6e32-4aee-c41a-4f0be8a43f19",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    }
   },
   "cell_type": "code",
   "source": [
    "df['Message'] = df['Message'].apply(lambda text: re.sub(r'([^\\w\\s])\\1+', r'\\1', text))\n",
    "df['Message'] = df['Message'].str.replace(r'([!?.])\\1+', r'\\1', regex=True)\n",
    "\n",
    "df['Word_Count'] = df['Message'].apply(lambda x: len(x.split()))\n",
    "print(df['Word_Count'].describe())\n",
    "sns.catplot(x=\"Word_Count\", data=df, kind=\"count\", aspect=3)"
   ],
   "id": "685e4f364780f966",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now convert the messages into conversation format. Messages are grouped by 3 min intervals."
   ],
   "metadata": {
    "id": "wE13Yee28Ilc"
   },
   "id": "wE13Yee28Ilc"
  },
  {
   "metadata": {
    "id": "dd8f73fd863ce131",
    "outputId": "18025db9-e015-4171-e883-b69a61baafab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_sharegpt_format(df):\n",
    "    return [{'from': 'gpt' if row['Author'] == 'world.soup' else 'human', 'value': row['Message']} for _, row in df.iterrows()]\n",
    "\n",
    "df['Conversation_ID'] = (df['Datetime'].diff() > pd.Timedelta('3min')).cumsum()\n",
    "conversations = [df_group for _, df_group in df.groupby('Conversation_ID')]\n",
    "results = [to_sharegpt_format(convo) for convo in conversations]\n",
    "results = [convo for convo in results if len(convo) > 1]\n",
    "print(len(results))"
   ],
   "id": "dd8f73fd863ce131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "d975c2d32f7f56c",
    "outputId": "1f37709b-5ed1-4af8-9618-48cfe047e424",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "random.sample(results, 1)"
   ],
   "id": "d975c2d32f7f56c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the preprocessed data"
   ],
   "metadata": {
    "id": "XimMH4js8V3R"
   },
   "id": "XimMH4js8V3R"
  },
  {
   "metadata": {
    "id": "31897193b2977a92"
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open('conversations.json', 'w+') as f:\n",
    "    json.dump(results, f, indent=4)"
   ],
   "id": "31897193b2977a92",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
